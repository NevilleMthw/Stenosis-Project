{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-08 19:21:16.302698: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.image as mpimg\n",
    "import splitfolders\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "# from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.optimizers import Adam as Adam\n",
    "from tensorflow.keras.optimizers import SGD as SGD\n",
    "from tensorflow.keras.optimizers import RMSprop as RMSprop\n",
    "from tensorflow.keras.optimizers import Adagrad as Adagrad\n",
    "from tensorflow.keras.optimizers import Adadelta as Adadelta\n",
    "from tensorflow.keras.optimizers import Adamax as Adamax\n",
    "from tensorflow.keras.optimizers import Nadam as Nadam\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "import shutil\n",
    "import torch\n",
    "import tensorflow_ranking as tfr\n",
    "from tensorflow_ranking.python.keras.metrics import MeanAveragePrecisionMetric\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from IPython.display import SVG\n",
    "from scipy import ndimage\n",
    "import pathlib as Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1816670047261293428\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10507335808\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17832557708567587722\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-08 19:22:49.916467: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-08 19:22:49.969313: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-08 19:22:49.970005: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-08 19:22:50.775859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-08 19:22:50.777504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2022-08-08 19:22:50.777603: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-08 19:22:51.924953: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-08-08 19:22:51.925154: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-08-08 19:22:52.737939: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-08 19:22:52.910079: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-08 19:22:53.727452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-08-08 19:22:53.835174: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-08-08 19:22:54.962697: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-08-08 19:22:54.963084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-08 19:22:54.964725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-08 19:22:54.966051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-08-08 19:22:54.979092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-08-08 19:22:58.946934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-08 19:22:58.946995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-08-08 19:22:58.947014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-08-08 19:22:58.954136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-08 19:22:58.955731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-08 19:22:58.957213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-08 19:22:58.958544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 10020 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "#check gpu availability\n",
    "print(device_lib.list_local_devices())\n",
    "# tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_path =r'C:/Users/conm/Desktop/Stenosis-Project/Stenosis detection/input'\n",
    "\n",
    "train_path = '/home/lunet/conm/Desktop/Stenosis-Project/output/train/stenosis'\n",
    "\n",
    "train_path1 = r'C:\\Users\\conm\\Desktop\\Stenosis-Project\\train_images'\n",
    "\n",
    "test_path = '/home/lunet/conm/Desktop/Stenosis-Project/test_images'\n",
    "\n",
    "val_path = '/home/lunet/conm/Desktop/Stenosis-Project/output/val/stenosis'\n",
    "\n",
    "train_path2 = r'C:\\Users\\conm\\Desktop\\Stenosis-Project\\Dataset_Reduced\\train\\images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14_024_2_0042.bmp</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>235</td>\n",
       "      <td>156</td>\n",
       "      <td>282</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14_031_4_0031.bmp</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>419</td>\n",
       "      <td>319</td>\n",
       "      <td>446</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14_046_5_0066.bmp</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>679</td>\n",
       "      <td>307</td>\n",
       "      <td>699</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14_010_6_0035.bmp</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>94</td>\n",
       "      <td>244</td>\n",
       "      <td>126</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14_014_1_0015.bmp</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>163</td>\n",
       "      <td>118</td>\n",
       "      <td>203</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6737</th>\n",
       "      <td>14_066_7_0059.bmp</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>229</td>\n",
       "      <td>100</td>\n",
       "      <td>254</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6738</th>\n",
       "      <td>14_088_8_0077.bmp</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>512</td>\n",
       "      <td>319</td>\n",
       "      <td>576</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6739</th>\n",
       "      <td>14_095_7_0045.bmp</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>199</td>\n",
       "      <td>218</td>\n",
       "      <td>229</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6740</th>\n",
       "      <td>14_051_6_0026.bmp</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>258</td>\n",
       "      <td>181</td>\n",
       "      <td>277</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6741</th>\n",
       "      <td>14_029_6_0098.bmp</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>84</td>\n",
       "      <td>404</td>\n",
       "      <td>114</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6742 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename  width  height     class  xmin  ymin  xmax  ymax\n",
       "0     14_024_2_0042.bmp    800     800  Stenosis   235   156   282   192\n",
       "1     14_031_4_0031.bmp    800     800  Stenosis   419   319   446   349\n",
       "2     14_046_5_0066.bmp   1000    1000  Stenosis   679   307   699   336\n",
       "3     14_010_6_0035.bmp    512     512  Stenosis    94   244   126   286\n",
       "4     14_014_1_0015.bmp    512     512  Stenosis   163   118   203   151\n",
       "...                 ...    ...     ...       ...   ...   ...   ...   ...\n",
       "6737  14_066_7_0059.bmp    800     800  Stenosis   229   100   254   160\n",
       "6738  14_088_8_0077.bmp    800     800  Stenosis   512   319   576   347\n",
       "6739  14_095_7_0045.bmp    800     800  Stenosis   199   218   229   273\n",
       "6740  14_051_6_0026.bmp    512     512  Stenosis   258   181   277   216\n",
       "6741  14_029_6_0098.bmp    800     800  Stenosis    84   404   114   432\n",
       "\n",
       "[6742 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read train_labels.csv\n",
    "train_labels_csv = pd.read_csv('train_labels.csv')\n",
    "train_labels_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14_029_7_0058.bmp</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>288</td>\n",
       "      <td>369</td>\n",
       "      <td>328</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14_024_1_0052.bmp</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>166</td>\n",
       "      <td>160</td>\n",
       "      <td>202</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14_095_2_0075.bmp</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>461</td>\n",
       "      <td>337</td>\n",
       "      <td>492</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14_075_6_0035.bmp</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>128</td>\n",
       "      <td>136</td>\n",
       "      <td>189</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14_081_7_0026.bmp</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>323</td>\n",
       "      <td>177</td>\n",
       "      <td>351</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>14_066_8_0028.bmp</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>125</td>\n",
       "      <td>175</td>\n",
       "      <td>161</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>14_048_1_0057.bmp</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>264</td>\n",
       "      <td>427</td>\n",
       "      <td>306</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>14_051_2_0051.bmp</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>82</td>\n",
       "      <td>297</td>\n",
       "      <td>110</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>14_051_2_0025.bmp</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>77</td>\n",
       "      <td>248</td>\n",
       "      <td>102</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>14_021_16_0077.bmp</td>\n",
       "      <td>608</td>\n",
       "      <td>608</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>149</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>833 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename  width  height     class  xmin  ymin  xmax  ymax\n",
       "0     14_029_7_0058.bmp    800     800  Stenosis   288   369   328   398\n",
       "1     14_024_1_0052.bmp    800     800  Stenosis   166   160   202   202\n",
       "2     14_095_2_0075.bmp    800     800  Stenosis   461   337   492   379\n",
       "3     14_075_6_0035.bmp    512     512  Stenosis   128   136   189   158\n",
       "4     14_081_7_0026.bmp    800     800  Stenosis   323   177   351   230\n",
       "..                  ...    ...     ...       ...   ...   ...   ...   ...\n",
       "828   14_066_8_0028.bmp    800     800  Stenosis   125   175   161   216\n",
       "829   14_048_1_0057.bmp   1000    1000  Stenosis   264   427   306   458\n",
       "830   14_051_2_0051.bmp    512     512  Stenosis    82   297   110   344\n",
       "831   14_051_2_0025.bmp    512     512  Stenosis    77   248   102   284\n",
       "832  14_021_16_0077.bmp    608     608  Stenosis   110    70   149   116\n",
       "\n",
       "[833 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_csv = pd.read_csv('test_labels.csv')\n",
    "test_labels_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14_029_5_0059.bmp</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>192</td>\n",
       "      <td>423</td>\n",
       "      <td>237</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14_006_1_0138.bmp</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>471</td>\n",
       "      <td>438</td>\n",
       "      <td>560</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14_087_1_0090.bmp</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>256</td>\n",
       "      <td>250</td>\n",
       "      <td>335</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14_021_37_0019.bmp</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>187</td>\n",
       "      <td>408</td>\n",
       "      <td>239</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14_057_3_0061.bmp</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>389</td>\n",
       "      <td>117</td>\n",
       "      <td>443</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>14_029_1_0068.bmp</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>297</td>\n",
       "      <td>265</td>\n",
       "      <td>356</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>14_095_2_0035.bmp</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>435</td>\n",
       "      <td>375</td>\n",
       "      <td>473</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>14_095_1_0080.bmp</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>501</td>\n",
       "      <td>498</td>\n",
       "      <td>546</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>14_048_3_0074.bmp</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>458</td>\n",
       "      <td>181</td>\n",
       "      <td>479</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>14_039_4_0021.bmp</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>Stenosis</td>\n",
       "      <td>299</td>\n",
       "      <td>195</td>\n",
       "      <td>318</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename  width  height     class  xmin  ymin  xmax  ymax\n",
       "0     14_029_5_0059.bmp    800     800  Stenosis   192   423   237   459\n",
       "1     14_006_1_0138.bmp    800     800  Stenosis   471   438   560   575\n",
       "2     14_087_1_0090.bmp    800     800  Stenosis   256   250   335   300\n",
       "3    14_021_37_0019.bmp    512     512  Stenosis   187   408   239   431\n",
       "4     14_057_3_0061.bmp   1000    1000  Stenosis   389   117   443   174\n",
       "..                  ...    ...     ...       ...   ...   ...   ...   ...\n",
       "745   14_029_1_0068.bmp    800     800  Stenosis   297   265   356   310\n",
       "746   14_095_2_0035.bmp    800     800  Stenosis   435   375   473   416\n",
       "747   14_095_1_0080.bmp    800     800  Stenosis   501   498   546   529\n",
       "748   14_048_3_0074.bmp   1000    1000  Stenosis   458   181   479   199\n",
       "749   14_039_4_0021.bmp    800     800  Stenosis   299   195   318   217\n",
       "\n",
       "[750 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels_csv = pd.read_csv('val_labels.csv')\n",
    "val_labels_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "train_targets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = []\n",
    "val_targets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "test_targets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train_labels_csv.iterrows():\n",
    "    (filename, width, height, class_name, xmin, ymin, xmax, ymax) = row\n",
    "\n",
    "    pic = cv2.imread(os.path.join(train_path,filename))\n",
    "    pic = cv2.resize(pic, (600, 600))\n",
    "    pic_arr = keras.preprocessing.image.img_to_array(pic)\n",
    "\n",
    "    train_images.append(pic)\n",
    "    train_targets.append((xmin, ymin, xmax, ymax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in val_labels_csv.iterrows():\n",
    "    (filename, width, height, class_name, xmin, ymin, xmax, ymax) = row\n",
    "\n",
    "    pic = cv2.imread(os.path.join(val_path,filename))\n",
    "    pic = cv2.resize(pic, (600, 600))\n",
    "    pic_arr = keras.preprocessing.image.img_to_array(pic)\n",
    "\n",
    "    val_images.append(pic)\n",
    "    val_targets.append((xmin, ymin, xmax, ymax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in test_labels_csv.iterrows():\n",
    "    (filename, width, height, class_name, xmin, ymin, xmax, ymax) = row\n",
    "\n",
    "    pic = cv2.imread(os.path.join(test_path,filename))\n",
    "    pic = cv2.resize(pic, (600, 600))\n",
    "    pic_arr = keras.preprocessing.image.img_to_array(pic)\n",
    "\n",
    "    test_images.append(pic)\n",
    "    test_targets.append((xmin, ymin, xmax, ymax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.asarray(train_images).astype('float32')\n",
    "train_targets = np.asarray(train_targets).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = np.asarray(val_images).astype('float32')\n",
    "val_targets = np.asarray(val_targets).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = np.asarray(test_images).astype('float32')\n",
    "test_targets = np.asarray(test_targets).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(833, 300, 300, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 300, 300, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6742, 300, 300, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize targets\n",
    "train_targets = train_targets / 256\n",
    "val_targets = val_targets / 256\n",
    "\n",
    "# Normalize images\n",
    "train_images = train_images / 255\n",
    "val_images = val_images / 255\n",
    "\n",
    "# Normalize test images\n",
    "test_images = test_images / 255\n",
    "test_targets = test_targets / 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGenerator = ImageDataGenerator(rotation_range=0, \n",
    "                                   zoom_range=0, \n",
    "                                   width_shift_range=0, \n",
    "                                   height_shift_range=0, \n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 33, 33, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 5, 5, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 419,364\n",
      "Trainable params: 419,364\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a new model for object detection and transfer learning\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(600, 600, 3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(4))\n",
    "# Add custom metric for mean average precision to model.compile\n",
    "# add learning rate\n",
    "\n",
    "model.compile(loss='mse', optimizer=SGD(learning_rate=0.1), metrics=[tfr.keras.metrics.MeanAveragePrecisionMetric()])\n",
    "# model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-08 21:06:46.141932: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 7281360000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "211/211 [==============================] - 7s 33ms/step - loss: 0.5276 - mean_average_precision_metric_1: 0.6758 - val_loss: 0.2355 - val_mean_average_precision_metric_1: 0.6964\n",
      "Epoch 2/100\n",
      "211/211 [==============================] - 7s 31ms/step - loss: 0.2384 - mean_average_precision_metric_1: 0.7016 - val_loss: 0.2252 - val_mean_average_precision_metric_1: 0.6996\n",
      "Epoch 3/100\n",
      "211/211 [==============================] - 7s 31ms/step - loss: 0.2052 - mean_average_precision_metric_1: 0.7165 - val_loss: 0.1698 - val_mean_average_precision_metric_1: 0.7346\n",
      "Epoch 4/100\n",
      "211/211 [==============================] - 7s 31ms/step - loss: 0.1764 - mean_average_precision_metric_1: 0.7404 - val_loss: 0.1262 - val_mean_average_precision_metric_1: 0.7608\n",
      "Epoch 5/100\n",
      "211/211 [==============================] - 7s 31ms/step - loss: 0.1250 - mean_average_precision_metric_1: 0.7594 - val_loss: 0.0994 - val_mean_average_precision_metric_1: 0.7671\n",
      "Epoch 6/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0799 - mean_average_precision_metric_1: 0.7770 - val_loss: 0.0431 - val_mean_average_precision_metric_1: 0.7806\n",
      "Epoch 7/100\n",
      "211/211 [==============================] - 7s 31ms/step - loss: 0.0593 - mean_average_precision_metric_1: 0.7880 - val_loss: 0.0287 - val_mean_average_precision_metric_1: 0.7843\n",
      "Epoch 8/100\n",
      "211/211 [==============================] - 7s 31ms/step - loss: 0.0446 - mean_average_precision_metric_1: 0.7944 - val_loss: 0.0218 - val_mean_average_precision_metric_1: 0.7875\n",
      "Epoch 9/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0398 - mean_average_precision_metric_1: 0.7882 - val_loss: 0.0207 - val_mean_average_precision_metric_1: 0.7861\n",
      "Epoch 10/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0342 - mean_average_precision_metric_1: 0.8040 - val_loss: 0.0159 - val_mean_average_precision_metric_1: 0.7914\n",
      "Epoch 11/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0313 - mean_average_precision_metric_1: 0.7954 - val_loss: 0.0178 - val_mean_average_precision_metric_1: 0.7887\n",
      "Epoch 12/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0287 - mean_average_precision_metric_1: 0.7956 - val_loss: 0.0145 - val_mean_average_precision_metric_1: 0.7912\n",
      "Epoch 13/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0288 - mean_average_precision_metric_1: 0.7941 - val_loss: 0.0157 - val_mean_average_precision_metric_1: 0.7891\n",
      "Epoch 14/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0267 - mean_average_precision_metric_1: 0.8024 - val_loss: 0.0132 - val_mean_average_precision_metric_1: 0.7896\n",
      "Epoch 15/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0249 - mean_average_precision_metric_1: 0.8022 - val_loss: 0.0161 - val_mean_average_precision_metric_1: 0.7903\n",
      "Epoch 16/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0243 - mean_average_precision_metric_1: 0.8064 - val_loss: 0.0146 - val_mean_average_precision_metric_1: 0.7901\n",
      "Epoch 17/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0231 - mean_average_precision_metric_1: 0.7899 - val_loss: 0.0100 - val_mean_average_precision_metric_1: 0.7923\n",
      "Epoch 18/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0229 - mean_average_precision_metric_1: 0.7898 - val_loss: 0.0117 - val_mean_average_precision_metric_1: 0.7906\n",
      "Epoch 19/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0223 - mean_average_precision_metric_1: 0.8048 - val_loss: 0.0086 - val_mean_average_precision_metric_1: 0.7913\n",
      "Epoch 20/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0218 - mean_average_precision_metric_1: 0.8031 - val_loss: 0.0105 - val_mean_average_precision_metric_1: 0.7904\n",
      "Epoch 21/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0217 - mean_average_precision_metric_1: 0.8044 - val_loss: 0.0086 - val_mean_average_precision_metric_1: 0.7927\n",
      "Epoch 22/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0204 - mean_average_precision_metric_1: 0.8073 - val_loss: 0.0136 - val_mean_average_precision_metric_1: 0.7920\n",
      "Epoch 23/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0213 - mean_average_precision_metric_1: 0.8027 - val_loss: 0.0081 - val_mean_average_precision_metric_1: 0.7923\n",
      "Epoch 24/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0199 - mean_average_precision_metric_1: 0.8010 - val_loss: 0.0099 - val_mean_average_precision_metric_1: 0.7926\n",
      "Epoch 25/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0192 - mean_average_precision_metric_1: 0.8011 - val_loss: 0.0102 - val_mean_average_precision_metric_1: 0.7919\n",
      "Epoch 26/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0197 - mean_average_precision_metric_1: 0.8025 - val_loss: 0.0073 - val_mean_average_precision_metric_1: 0.7913\n",
      "Epoch 27/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0181 - mean_average_precision_metric_1: 0.8016 - val_loss: 0.0064 - val_mean_average_precision_metric_1: 0.7930\n",
      "Epoch 28/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0178 - mean_average_precision_metric_1: 0.8073 - val_loss: 0.0070 - val_mean_average_precision_metric_1: 0.7911\n",
      "Epoch 29/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0180 - mean_average_precision_metric_1: 0.7997 - val_loss: 0.0096 - val_mean_average_precision_metric_1: 0.7920\n",
      "Epoch 30/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0183 - mean_average_precision_metric_1: 0.8008 - val_loss: 0.0075 - val_mean_average_precision_metric_1: 0.7932\n",
      "Epoch 31/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0185 - mean_average_precision_metric_1: 0.8025 - val_loss: 0.0068 - val_mean_average_precision_metric_1: 0.7930\n",
      "Epoch 32/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0174 - mean_average_precision_metric_1: 0.7922 - val_loss: 0.0078 - val_mean_average_precision_metric_1: 0.7928\n",
      "Epoch 33/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0179 - mean_average_precision_metric_1: 0.7943 - val_loss: 0.0064 - val_mean_average_precision_metric_1: 0.7928\n",
      "Epoch 34/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0173 - mean_average_precision_metric_1: 0.8020 - val_loss: 0.0067 - val_mean_average_precision_metric_1: 0.7927\n",
      "Epoch 35/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0171 - mean_average_precision_metric_1: 0.7966 - val_loss: 0.0068 - val_mean_average_precision_metric_1: 0.7913\n",
      "Epoch 36/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0176 - mean_average_precision_metric_1: 0.8010 - val_loss: 0.0058 - val_mean_average_precision_metric_1: 0.7923\n",
      "Epoch 37/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0173 - mean_average_precision_metric_1: 0.8033 - val_loss: 0.0066 - val_mean_average_precision_metric_1: 0.7936\n",
      "Epoch 38/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0168 - mean_average_precision_metric_1: 0.8005 - val_loss: 0.0071 - val_mean_average_precision_metric_1: 0.7926\n",
      "Epoch 39/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0163 - mean_average_precision_metric_1: 0.8013 - val_loss: 0.0059 - val_mean_average_precision_metric_1: 0.7938\n",
      "Epoch 40/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0157 - mean_average_precision_metric_1: 0.8021 - val_loss: 0.0060 - val_mean_average_precision_metric_1: 0.7931\n",
      "Epoch 41/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0160 - mean_average_precision_metric_1: 0.7993 - val_loss: 0.0054 - val_mean_average_precision_metric_1: 0.7938\n",
      "Epoch 42/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0164 - mean_average_precision_metric_1: 0.7960 - val_loss: 0.0050 - val_mean_average_precision_metric_1: 0.7932\n",
      "Epoch 43/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0152 - mean_average_precision_metric_1: 0.8080 - val_loss: 0.0051 - val_mean_average_precision_metric_1: 0.7940\n",
      "Epoch 44/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0152 - mean_average_precision_metric_1: 0.8038 - val_loss: 0.0086 - val_mean_average_precision_metric_1: 0.7941\n",
      "Epoch 45/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0148 - mean_average_precision_metric_1: 0.8038 - val_loss: 0.0052 - val_mean_average_precision_metric_1: 0.7937\n",
      "Epoch 46/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0147 - mean_average_precision_metric_1: 0.8068 - val_loss: 0.0047 - val_mean_average_precision_metric_1: 0.7937\n",
      "Epoch 47/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0148 - mean_average_precision_metric_1: 0.8014 - val_loss: 0.0045 - val_mean_average_precision_metric_1: 0.7941\n",
      "Epoch 48/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0150 - mean_average_precision_metric_1: 0.8046 - val_loss: 0.0048 - val_mean_average_precision_metric_1: 0.7938\n",
      "Epoch 49/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0150 - mean_average_precision_metric_1: 0.7981 - val_loss: 0.0049 - val_mean_average_precision_metric_1: 0.7943\n",
      "Epoch 50/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0151 - mean_average_precision_metric_1: 0.7973 - val_loss: 0.0052 - val_mean_average_precision_metric_1: 0.7946\n",
      "Epoch 51/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0145 - mean_average_precision_metric_1: 0.7998 - val_loss: 0.0048 - val_mean_average_precision_metric_1: 0.7951\n",
      "Epoch 52/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0153 - mean_average_precision_metric_1: 0.8009 - val_loss: 0.0052 - val_mean_average_precision_metric_1: 0.7944\n",
      "Epoch 53/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0150 - mean_average_precision_metric_1: 0.8001 - val_loss: 0.0065 - val_mean_average_precision_metric_1: 0.7938\n",
      "Epoch 54/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0153 - mean_average_precision_metric_1: 0.8068 - val_loss: 0.0047 - val_mean_average_precision_metric_1: 0.7946\n",
      "Epoch 55/100\n",
      "211/211 [==============================] - 7s 32ms/step - loss: 0.0148 - mean_average_precision_metric_1: 0.8082 - val_loss: 0.0048 - val_mean_average_precision_metric_1: 0.7944\n",
      "Epoch 56/100\n",
      "167/211 [======================>.......] - ETA: 1s - loss: 0.0139 - mean_average_precision_metric_1: 0.8020"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/lunet/conm/Desktop/Stenosis-Project/new_model.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blnx-n109-10.lunet.lboro.ac.uk/home/lunet/conm/Desktop/Stenosis-Project/new_model.ipynb#ch0000029vscode-remote?line=2'>3</a>\u001b[0m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mset_seed(\u001b[39m15\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blnx-n109-10.lunet.lboro.ac.uk/home/lunet/conm/Desktop/Stenosis-Project/new_model.ipynb#ch0000029vscode-remote?line=3'>4</a>\u001b[0m \u001b[39m# Model training\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blnx-n109-10.lunet.lboro.ac.uk/home/lunet/conm/Desktop/Stenosis-Project/new_model.ipynb#ch0000029vscode-remote?line=4'>5</a>\u001b[0m \u001b[39m# Add confidence threshold to filter out false positives\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blnx-n109-10.lunet.lboro.ac.uk/home/lunet/conm/Desktop/Stenosis-Project/new_model.ipynb#ch0000029vscode-remote?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_images, train_targets, validation_data\u001b[39m=\u001b[39;49m(val_images, val_targets), epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[es])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blnx-n109-10.lunet.lboro.ac.uk/home/lunet/conm/Desktop/Stenosis-Project/new_model.ipynb#ch0000029vscode-remote?line=8'>9</a>\u001b[0m \u001b[39m# confidence_threshold = 0.5\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blnx-n109-10.lunet.lboro.ac.uk/home/lunet/conm/Desktop/Stenosis-Project/new_model.ipynb#ch0000029vscode-remote?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39mfit(dataGenerator\u001b[39m.\u001b[39mflow(train_images, train_targets, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blnx-n109-10.lunet.lboro.ac.uk/home/lunet/conm/Desktop/Stenosis-Project/new_model.ipynb#ch0000029vscode-remote?line=11'>12</a>\u001b[0m                             validation_data\u001b[39m=\u001b[39m(val_images, val_targets), \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Blnx-n109-10.lunet.lboro.ac.uk/home/lunet/conm/Desktop/Stenosis-Project/new_model.ipynb#ch0000029vscode-remote?line=12'>13</a>\u001b[0m                             epochs\u001b[39m=\u001b[39m\u001b[39m150\u001b[39m, callbacks\u001b[39m=\u001b[39mes, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/stenosispyv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1105\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1105\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1107\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/stenosispyv/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:454\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \n\u001b[1;32m    449\u001b[0m \u001b[39mArguments:\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 454\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/.conda/envs/stenosispyv/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:296\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    295\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 296\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(hook))\n",
      "File \u001b[0;32m~/.conda/envs/stenosispyv/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:316\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    314\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 316\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    319\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/.conda/envs/stenosispyv/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m    355\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(callback, \u001b[39m'\u001b[39m\u001b[39m_supports_tf_logs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 356\u001b[0m   hook(batch, logs)\n\u001b[1;32m    357\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m   \u001b[39mif\u001b[39;00m numpy_logs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# Only convert once.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/stenosispyv/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:1020\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1020\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m~/.conda/envs/stenosispyv/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:1084\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1083\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1084\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49mto_numpy_or_python_type(logs)\n\u001b[1;32m   1085\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/stenosispyv/lib/python3.9/site-packages/tensorflow/python/keras/utils/tf_utils.py:514\u001b[0m, in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(x) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m x\n\u001b[1;32m    512\u001b[0m   \u001b[39mreturn\u001b[39;00m t  \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m--> 514\u001b[0m \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m~/.conda/envs/stenosispyv/lib/python3.9/site-packages/tensorflow/python/util/nest.py:659\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    656\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    658\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    660\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/.conda/envs/stenosispyv/lib/python3.9/site-packages/tensorflow/python/util/nest.py:659\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    655\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    656\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    658\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    660\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/.conda/envs/stenosispyv/lib/python3.9/site-packages/tensorflow/python/keras/utils/tf_utils.py:510\u001b[0m, in \u001b[0;36mto_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    509\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, ops\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 510\u001b[0m     x \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    511\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(x) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m x\n\u001b[1;32m    512\u001b[0m   \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/.conda/envs/stenosispyv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1071\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \n\u001b[1;32m   1050\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1071\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/.conda/envs/stenosispyv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1037\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1036\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1037\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1038\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m     six\u001b[39m.\u001b[39mraise_from(core\u001b[39m.\u001b[39m_status_to_exception(e\u001b[39m.\u001b[39mcode, e\u001b[39m.\u001b[39mmessage), \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(15)\n",
    "tf.random.set_seed(15)\n",
    "# Model training\n",
    "# Add confidence threshold to filter out false positives\n",
    "model.fit(train_images, train_targets, validation_data=(val_images, val_targets), epochs=100, batch_size=32, callbacks=[es])\n",
    "\n",
    "\n",
    "# confidence_threshold = 0.5\n",
    "\n",
    "model.fit(dataGenerator.flow(train_images, train_targets, batch_size=32),\n",
    "                            validation_data=(val_images, val_targets), \n",
    "                            epochs=150, callbacks=es, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 11ms/step - loss: 0.0047 - mean_average_precision_metric_11: 0.7956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.004733323585242033, 0.7956182360649109]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test trained modeel\n",
    "test_map = model.evaluate(test_images, test_targets)\n",
    "test_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('stenosispyv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0da6bbdad7e7ac120af1fededa8862de78c9ff624c00dc9707da58477229c33e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
